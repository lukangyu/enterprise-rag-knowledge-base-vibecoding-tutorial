# 企业级GraphRAG知识库系统 - 部署运维文档

> 文档版本: v1.0  
> 创建日期: 2026-02-17  
> 文档状态: 正式版  
> 依据文档: 系统架构设计文档v2.0、技术选型文档v2.2、开发计划文档v1.0  
> 适用环境: 生产环境 / 测试环境 / 开发环境

---

## 目录

- [1. 系统环境要求](#1-系统环境要求)
- [2. 部署架构说明](#2-部署架构说明)
- [3. 详细部署步骤](#3-详细部署步骤)
- [4. 配置文件说明](#4-配置文件说明)
- [5. 数据库初始化](#5-数据库初始化)
- [6. 服务启动与验证](#6-服务启动与验证)
- [7. 日常运维操作指南](#7-日常运维操作指南)
- [8. 监控与告警](#8-监控与告警)
- [9. 日志管理](#9-日志管理)
- [10. 备份与恢复策略](#10-备份与恢复策略)
- [11. 常见问题排查与解决方案](#11-常见问题排查与解决方案)
- [12. 系统更新与版本升级](#12-系统更新与版本升级)
- [13. 安全注意事项](#13-安全注意事项)
- [14. 应急处理预案](#14-应急处理预案)
- [15. 运维检查清单](#15-运维检查清单)

---

## 1. 系统环境要求

### 1.1 硬件要求

#### 1.1.1 MVP/开发环境

| 组件 | 最低配置 | 推荐配置 | 说明 |
|------|---------|---------|------|
| **CPU** | 4核 | 8核 | 支持AVX2指令集 |
| **内存** | 16GB | 32GB | 包含向量数据库和图谱数据库 |
| **存储** | 100GB SSD | 500GB SSD | NVMe优先 |
| **网络** | 100Mbps | 1Gbps | 内网带宽 |

#### 1.1.2 生产环境

| 组件 | 最低配置 | 推荐配置 | 数量 | 说明 |
|------|---------|---------|------|------|
| **应用服务器** | 8核16GB | 16核32GB | 3+ | Spring Boot服务 |
| **AI服务器** | 8核32GB | 16核64GB | 2+ | FastAPI服务 |
| **GPU服务器** | A100 80GB | A100 80GB x4 | 1+ | 本地LLM推理（可选） |
| **数据库服务器** | 16核64GB | 32核128GB | 3+ | PostgreSQL主从 |
| **向量数据库** | 16核64GB | 32核128GB | 3+ | Milvus集群 |
| **图数据库** | 8核32GB | 16核64GB | 3+ | Neo4j集群 |
| **缓存服务器** | 8核32GB | 16核64GB | 3+ | Redis集群 |
| **存储** | 1TB SSD | 5TB SSD | - | NVMe优先 |

### 1.2 软件要求

#### 1.2.1 操作系统

| 操作系统 | 版本要求 | 架构 | 说明 |
|---------|---------|------|------|
| **Ubuntu Server** | 22.04 LTS | x86_64 | 推荐，生产环境首选 |
| **CentOS** | 8+ / Rocky Linux 8+ | x86_64 | 企业环境常用 |
| **Debian** | 12+ | x86_64 | 开发环境可用 |
| **Windows Server** | 2022+ | x86_64 | 仅开发测试环境 |

#### 1.2.2 基础软件

| 软件 | 版本要求 | 用途 | 安装命令 |
|------|---------|------|---------|
| **Docker** | 24.0+ | 容器运行时 | `curl -fsSL https://get.docker.com \| sh` |
| **Docker Compose** | 2.20+ | 容器编排 | `sudo apt install docker-compose-plugin` |
| **Kubernetes** | 1.28+ | 容器编排（生产） | 见K8s安装章节 |
| **Git** | 2.40+ | 版本控制 | `sudo apt install git` |
| **curl/wget** | latest | 网络工具 | `sudo apt install curl wget` |
| **htop** | latest | 系统监控 | `sudo apt install htop` |

#### 1.2.3 运行时环境

| 运行时 | 版本要求 | 用途 | 安装方式 |
|-------|---------|------|---------|
| **Java JDK** | 17+ | Spring Boot服务 | Docker镜像内置 |
| **Python** | 3.11+ | FastAPI服务 | Docker镜像内置 |
| **Node.js** | 20+ | 前端构建 | Docker镜像内置 |

### 1.3 网络要求

#### 1.3.1 端口规划

| 服务 | 端口 | 协议 | 说明 |
|------|------|------|------|
| **Nginx/APISIX** | 80, 443 | HTTP/HTTPS | 入口网关 |
| **APISIX Admin** | 9180 | HTTP | API管理 |
| **Spring Boot** | 8080 | HTTP | 业务服务 |
| **FastAPI** | 8000 | HTTP | AI服务 |
| **PostgreSQL** | 5432 | TCP | 关系数据库 |
| **Milvus** | 19530, 9091 | gRPC/HTTP | 向量数据库 |
| **Neo4j** | 7474, 7687 | HTTP/Bolt | 图数据库 |
| **Redis** | 6379 | TCP | 缓存服务 |
| **Kafka** | 9092 | TCP | 消息队列 |
| **Zookeeper** | 2181 | TCP | Kafka协调 |
| **MinIO** | 9000, 9001 | HTTP/API | 对象存储 |
| **Prometheus** | 9090 | HTTP | 监控系统 |
| **Grafana** | 3000 | HTTP | 可视化 |
| **Elasticsearch** | 9200, 9300 | HTTP/TCP | 日志存储 |
| **Kibana** | 5601 | HTTP | 日志展示 |

#### 1.3.2 网络策略

```
┌─────────────────────────────────────────────────────────────────────┐
│                        网络安全组规则                                 │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│   入站规则 (Inbound Rules):                                          │
│   ┌─────────────────────────────────────────────────────────────┐  │
│   │  端口范围    │ 源地址          │ 协议 │ 说明                  │  │
│   ├─────────────────────────────────────────────────────────────┤  │
│   │  22         │ 办公网IP段      │ TCP  │ SSH管理访问           │  │
│   │  80, 443    │ 0.0.0.0/0       │ TCP  │ Web服务入口           │  │
│   │  8080       │ 内网网段        │ TCP  │ Spring Boot服务       │  │
│   │  8000       │ 内网网段        │ TCP  │ FastAPI服务           │  │
│   │  5432       │ 应用服务器组    │ TCP  │ PostgreSQL            │  │
│   │  19530      │ AI服务器组      │ TCP  │ Milvus                │  │
│   │  7687       │ AI服务器组      │ TCP  │ Neo4j Bolt            │  │
│   │  6379       │ 应用服务器组    │ TCP  │ Redis                 │  │
│   │  9092       │ 应用服务器组    │ TCP  │ Kafka                 │  │
│   │  9000       │ 应用服务器组    │ TCP  │ MinIO                 │  │
│   └─────────────────────────────────────────────────────────────┘  │
│                                                                     │
│   出站规则 (Outbound Rules):                                         │
│   ┌─────────────────────────────────────────────────────────────┐  │
│   │  全部端口    │ 0.0.0.0/0       │ 全部 │ 允许全部出站流量      │  │
│   └─────────────────────────────────────────────────────────────┘  │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

### 1.4 存储要求

| 存储类型 | 最小容量 | 推荐容量 | 用途 | IOPS要求 |
|---------|---------|---------|------|---------|
| **系统盘** | 50GB | 100GB | 操作系统 | 3000+ |
| **数据盘** | 500GB | 2TB | 数据库存储 | 10000+ |
| **日志盘** | 100GB | 500GB | 日志存储 | 1000+ |
| **备份盘** | 1TB | 5TB | 数据备份 | 500+ |

### 1.5 环境检查脚本

```bash
#!/bin/bash
# 环境检查脚本 - check_environment.sh

echo "=========================================="
echo "GraphRAG系统环境检查"
echo "=========================================="

# 检查操作系统
echo -e "\n[1] 操作系统检查"
OS=$(cat /etc/os-release | grep PRETTY_NAME | cut -d'"' -f2)
echo "操作系统: $OS"

# 检查CPU
echo -e "\n[2] CPU检查"
CPU_CORES=$(nproc)
echo "CPU核心数: $CPU_CORES"
if [ $CPU_CORES -lt 4 ]; then
    echo "警告: CPU核心数不足4核，建议至少8核"
fi

# 检查内存
echo -e "\n[3] 内存检查"
TOTAL_MEM=$(free -h | grep Mem | awk '{print $2}')
AVAIL_MEM=$(free -h | grep Mem | awk '{print $7}')
echo "总内存: $TOTAL_MEM"
echo "可用内存: $AVAIL_MEM"

# 检查磁盘
echo -e "\n[4] 磁盘检查"
df -h | grep -E "Filesystem|/$|/data"

# 检查Docker
echo -e "\n[5] Docker检查"
if command -v docker &> /dev/null; then
    DOCKER_VERSION=$(docker --version)
    echo "Docker版本: $DOCKER_VERSION"
else
    echo "错误: Docker未安装"
fi

# 检查Docker Compose
echo -e "\n[6] Docker Compose检查"
if command -v docker-compose &> /dev/null; then
    COMPOSE_VERSION=$(docker-compose --version)
    echo "$COMPOSE_VERSION"
elif docker compose version &> /dev/null; then
    COMPOSE_VERSION=$(docker compose version)
    echo "$COMPOSE_VERSION"
else
    echo "错误: Docker Compose未安装"
fi

# 检查网络端口
echo -e "\n[7] 端口占用检查"
PORTS=(80 443 8080 8000 5432 19530 7687 6379 9092 9000)
for PORT in "${PORTS[@]}"; do
    if netstat -tuln 2>/dev/null | grep -q ":$PORT "; then
        echo "警告: 端口 $PORT 已被占用"
    else
        echo "端口 $PORT: 可用"
    fi
done

# 检查GPU（可选）
echo -e "\n[8] GPU检查"
if command -v nvidia-smi &> /dev/null; then
    nvidia-smi --query-gpu=name,memory.total --format=csv,noheader
else
    echo "GPU: 未检测到或驱动未安装（可选）"
fi

echo -e "\n=========================================="
echo "环境检查完成"
echo "=========================================="
```

---

## 2. 部署架构说明

### 2.1 部署架构总览

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                           生产环境部署架构                                        │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                 │
│   ┌─────────────────────────────────────────────────────────────────────────┐  │
│   │                          用户接入层                                      │  │
│   │  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐         │  │
│   │  │   CDN/静态加速   │  │   负载均衡SLB   │  │   WAF防护       │         │  │
│   │  │   静态资源缓存   │  │   4/7层分发     │  │   安全防护      │         │  │
│   │  └─────────────────┘  └─────────────────┘  └─────────────────┘         │  │
│   └─────────────────────────────────────────────────────────────────────────┘  │
│                                       ↓                                         │
│   ┌─────────────────────────────────────────────────────────────────────────┐  │
│   │                          Kubernetes集群                                  │  │
│   │  ┌───────────────────────────────────────────────────────────────────┐ │  │
│   │  │                        Ingress/APISIX                              │ │  │
│   │  │  路由转发 │ 认证鉴权 │ 限流熔断 │ 日志追踪 │ 负载均衡              │ │  │
│   │  └───────────────────────────────────────────────────────────────────┘ │  │
│   │  ┌───────────────────────────────────────────────────────────────────┐ │  │
│   │  │                        业务服务Pods                                │ │  │
│   │  │  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐    │ │  │
│   │  │  │user-svc │ │doc-svc  │ │auth-svc │ │chat-svc │ │search   │    │ │  │
│   │  │  │ x3      │ │ x3      │ │ x3      │ │ x3      │ │ x3      │    │ │  │
│   │  │  └─────────┘ └─────────┘ └─────────┘ └─────────┘ └─────────┘    │ │  │
│   │  └───────────────────────────────────────────────────────────────────┘ │  │
│   │  ┌───────────────────────────────────────────────────────────────────┐ │  │
│   │  │                        GraphRAG服务Pods                            │ │  │
│   │  │  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐    │ │  │
│   │  │  │parse    │ │embed    │ │kg-build │ │rerank   │ │llm      │    │ │  │
│   │  │  │ x2      │ │ x2      │ │ x2      │ │ x2      │ │ x2(GPU) │    │ │  │
│   │  │  └─────────┘ └─────────┘ └─────────┘ └─────────┘ └─────────┘    │ │  │
│   │  └───────────────────────────────────────────────────────────────────┘ │  │
│   └─────────────────────────────────────────────────────────────────────────┘  │
│                                       ↓                                         │
│   ┌─────────────────────────────────────────────────────────────────────────┐  │
│   │                          数据存储层                                      │  │
│   │  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐         │  │
│   │  │ PostgreSQL      │  │ Milvus Cluster  │  │ Neo4j Cluster   │         │  │
│   │  │ 主从复制        │  │ 3节点集群       │  │ 3节点集群       │         │  │
│   │  └─────────────────┘  └─────────────────┘  └─────────────────┘         │  │
│   │  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐         │  │
│   │  │ Redis Cluster   │  │ Kafka Cluster   │  │ MinIO Cluster   │         │  │
│   │  │ 6节点集群       │  │ 3节点集群       │  │ 4节点集群       │         │  │
│   │  └─────────────────┘  └─────────────────┘  └─────────────────┘         │  │
│   └─────────────────────────────────────────────────────────────────────────┘  │
│                                                                                 │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### 2.2 MVP部署架构

```
┌─────────────────────────────────────────────────────────────────────┐
│                     MVP单机部署架构 (Docker Compose)                  │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│   ┌─────────────────────────────────────────────────────────────┐  │
│   │                      Nginx容器                               │  │
│   │  端口: 80, 443 | 静态资源 + 反向代理                         │  │
│   └─────────────────────────────────────────────────────────────┘  │
│                                │                                    │
│              ┌─────────────────┼─────────────────┐                 │
│              ↓                 ↓                 ↓                 │
│   ┌───────────────┐  ┌───────────────┐  ┌───────────────┐         │
│   │ Spring Boot   │  │   FastAPI     │  │   前端静态    │         │
│   │ 端口: 8080    │  │   端口: 8000  │  │   端口: 80    │         │
│   └───────────────┘  └───────────────┘  └───────────────┘         │
│              │                 │                                    │
│              └─────────────────┼─────────────────┐                 │
│                                ↓                 ↓                 │
│   ┌─────────────────────────────────────────────────────────────┐  │
│   │                      数据库容器组                            │  │
│   │  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐           │  │
│   │  │PostgreSQL│ │ Milvus  │ │  Neo4j  │ │  Redis  │           │  │
│   │  │ :5432   │ │ :19530  │ │  :7687  │ │  :6379  │           │  │
│   │  └─────────┘ └─────────┘ └─────────┘ └─────────┘           │  │
│   │  ┌─────────┐ ┌─────────┐                                   │  │
│   │  │  MinIO  │ │  Kafka  │                                   │  │
│   │  │  :9000  │ │  :9092  │                                   │  │
│   │  └─────────┘ └─────────┘                                   │  │
│   └─────────────────────────────────────────────────────────────┘  │
│                                                                     │
│   AI服务（外部API）：                                               │
│   ├── Qwen-Embedding API                                          │
│   ├── Qwen-Reranker API                                           │
│   └── Qwen2.5-Max API                                             │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

### 2.3 服务依赖关系

```
┌─────────────────────────────────────────────────────────────────────┐
│                        服务启动依赖顺序                               │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│   第一层（基础设施，无依赖）：                                        │
│   ├── PostgreSQL    - 关系数据库                                    │
│   ├── Redis         - 缓存服务                                      │
│   ├── MinIO         - 对象存储                                      │
│   └── Zookeeper     - Kafka协调服务                                 │
│                                                                     │
│   第二层（依赖第一层）：                                              │
│   ├── Kafka         - 消息队列（依赖Zookeeper）                      │
│   ├── Milvus        - 向量数据库（依赖MinIO）                        │
│   └── Neo4j         - 图数据库                                      │
│                                                                     │
│   第三层（核心服务，依赖第一、二层）：                                 │
│   ├── Spring Boot   - 业务服务（依赖全部数据库）                     │
│   └── FastAPI       - AI服务（依赖全部数据库）                       │
│                                                                     │
│   第四层（网关和前端，依赖第三层）：                                   │
│   ├── APISIX        - API网关（依赖后端服务）                        │
│   └── Nginx/Frontend- 前端服务（依赖API网关）                        │
│                                                                     │
│   第五层（监控运维，可选）：                                          │
│   ├── Prometheus    - 指标采集                                      │
│   ├── Grafana       - 可视化展示                                    │
│   ├── Elasticsearch - 日志存储                                      │
│   └── Kibana        - 日志展示                                      │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

---

## 3. 详细部署步骤

### 3.1 前置条件检查

#### 3.1.1 系统准备

```bash
# 1. 更新系统
sudo apt update && sudo apt upgrade -y

# 2. 安装基础工具
sudo apt install -y \
    curl \
    wget \
    git \
    vim \
    htop \
    net-tools \
    lsof \
    jq \
    unzip \
    software-properties-common

# 3. 设置时区
sudo timedatectl set-timezone Asia/Shanghai

# 4. 设置系统语言
sudo locale-gen en_US.UTF-8
sudo update-locale LANG=en_US.UTF-8

# 5. 优化系统参数
sudo tee /etc/sysctl.d/99-graphrag.conf << EOF
# 网络优化
net.core.somaxconn = 65535
net.ipv4.tcp_max_syn_backlog = 65535
net.ipv4.ip_local_port_range = 1024 65535
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_fin_timeout = 30

# 内存优化
vm.swappiness = 10
vm.overcommit_memory = 1
vm.max_map_count = 262144

# 文件描述符
fs.file-max = 2097152
fs.nr_open = 2097152
EOF
sudo sysctl -p /etc/sysctl.d/99-graphrag.conf

# 6. 设置文件描述符限制
sudo tee -a /etc/security/limits.conf << EOF
* soft nofile 65535
* hard nofile 65535
* soft nproc 65535
* hard nproc 65535
root soft nofile 65535
root hard nofile 65535
EOF
```

#### 3.1.2 Docker安装

```bash
# 1. 安装Docker
curl -fsSL https://get.docker.com | sh

# 2. 配置Docker镜像加速（国内环境）
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json << EOF
{
    "registry-mirrors": [
        "https://docker.mirrors.ustc.edu.cn",
        "https://hub-mirror.c.163.com",
        "https://mirror.baidubce.com"
    ],
    "log-driver": "json-file",
    "log-opts": {
        "max-size": "100m",
        "max-file": "3"
    },
    "storage-driver": "overlay2",
    "live-restore": true,
    "default-ulimits": {
        "nofile": {
            "Name": "nofile",
            "Hard": 65535,
            "Soft": 65535
        }
    }
}
EOF

# 3. 启动Docker服务
sudo systemctl daemon-reload
sudo systemctl enable docker
sudo systemctl start docker

# 4. 验证Docker安装
docker --version
docker run hello-world

# 5. 安装Docker Compose
sudo apt install -y docker-compose-plugin
docker compose version
```

#### 3.1.3 创建目录结构

```bash
# 创建项目目录
sudo mkdir -p /opt/graphrag/{config,data,logs,backup,scripts}
sudo mkdir -p /opt/graphrag/data/{postgres,milvus,neo4j,redis,minio,kafka}
sudo mkdir -p /opt/graphrag/logs/{app,milvus,neo4j,redis,kafka}

# 设置权限
sudo chown -R $USER:$USER /opt/graphrag
chmod -R 755 /opt/graphrag
```

### 3.2 Docker Compose部署（MVP/开发环境）

#### 3.2.1 创建Docker Compose配置文件

```yaml
# /opt/graphrag/docker-compose.yml
version: '3.8'

services:
  # ==================== 数据库层 ====================
  
  # PostgreSQL - 关系数据库
  postgres:
    image: postgres:15-alpine
    container_name: graphrag-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-graphrag}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-graphrag123}
      POSTGRES_DB: ${POSTGRES_DB:-graphrag}
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init/sql:/docker-entrypoint-initdb.d:ro
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-graphrag}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - graphrag-network

  # Redis - 缓存服务
  redis:
    image: redis:7-alpine
    container_name: graphrag-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-redis123}
    volumes:
      - redis_data:/data
    ports:
      - "${REDIS_PORT:-6379}:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-redis123}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - graphrag-network

  # MinIO - 对象存储
  minio:
    image: minio/minio:RELEASE.2024-01-16T16-07-38Z
    container_name: graphrag-minio
    restart: unless-stopped
    environment:
      MINIO_ROOT_USER: ${MINIO_USER:-admin}
      MINIO_ROOT_PASSWORD: ${MINIO_PASSWORD:-minio123456}
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    ports:
      - "${MINIO_API_PORT:-9000}:9000"
      - "${MINIO_CONSOLE_PORT:-9001}:9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - graphrag-network

  # Milvus - 向量数据库
  etcd:
    image: quay.io/coreos/etcd:v3.5.5
    container_name: graphrag-etcd
    restart: unless-stopped
    environment:
      ETCD_AUTO_COMPACTION_MODE: revision
      ETCD_AUTO_COMPACTION_RETENTION: "1000"
      ETCD_QUOTA_BACKEND_BYTES: "4294967296"
      ETCD_SNAPSHOT_COUNT: "50000"
    volumes:
      - etcd_data:/etcd
    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - graphrag-network

  minio-milvus:
    image: minio/minio:RELEASE.2024-01-16T16-07-38Z
    container_name: graphrag-minio-milvus
    restart: unless-stopped
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /minio_data
    volumes:
      - milvus_minio_data:/minio_data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - graphrag-network

  milvus:
    image: milvusdb/milvus:v2.3.3
    container_name: graphrag-milvus
    restart: unless-stopped
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio-milvus:9000
    volumes:
      - milvus_data:/var/lib/milvus
    ports:
      - "${MILVUS_PORT:-19530}:19530"
      - "${MILVUS_METRICS_PORT:-9091}:9091"
    depends_on:
      - etcd
      - minio-milvus
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - graphrag-network

  # Neo4j - 图数据库
  neo4j:
    image: neo4j:5.15.0-community
    container_name: graphrag-neo4j
    restart: unless-stopped
    environment:
      NEO4J_AUTH: neo4j/${NEO4J_PASSWORD:-neo4j123}
      NEO4J_PLUGINS: '["apoc"]'
      NEO4J_dbms_memory_heap_initial__size: "512m"
      NEO4J_dbms_memory_heap_max__size: "2G"
      NEO4J_dbms_memory_pagecache_size: "512m"
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_import:/var/lib/neo4j/import
      - neo4j_plugins:/plugins
    ports:
      - "${NEO4J_HTTP_PORT:-7474}:7474"
      - "${NEO4J_BOLT_PORT:-7687}:7687"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7474"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - graphrag-network

  # Kafka - 消息队列
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: graphrag-zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    networks:
      - graphrag-network

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: graphrag-kafka
    restart: unless-stopped
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    volumes:
      - kafka_data:/var/lib/kafka/data
    ports:
      - "${KAFKA_PORT:-9092}:9092"
    depends_on:
      - zookeeper
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - graphrag-network

  # ==================== 应用层 ====================
  
  # Spring Boot - 业务服务
  springboot:
    build:
      context: ./backend/springboot
      dockerfile: Dockerfile
    container_name: graphrag-springboot
    restart: unless-stopped
    environment:
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE:-prod}
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/${POSTGRES_DB:-graphrag}
      SPRING_DATASOURCE_USERNAME: ${POSTGRES_USER:-graphrag}
      SPRING_DATASOURCE_PASSWORD: ${POSTGRES_PASSWORD:-graphrag123}
      SPRING_REDIS_HOST: redis
      SPRING_REDIS_PORT: 6379
      SPRING_REDIS_PASSWORD: ${REDIS_PASSWORD:-redis123}
      MINIO_ENDPOINT: http://minio:9000
      MINIO_ACCESS_KEY: ${MINIO_USER:-admin}
      MINIO_SECRET_KEY: ${MINIO_PASSWORD:-minio123456}
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USERNAME: neo4j
      NEO4J_PASSWORD: ${NEO4J_PASSWORD:-neo4j123}
      MILVUS_HOST: milvus
      MILVUS_PORT: 19530
      JWT_SECRET: ${JWT_SECRET:-your-jwt-secret-key-change-in-production}
      JWT_EXPIRATION: 86400000
    volumes:
      - ./logs/app:/app/logs
    ports:
      - "${SPRINGBOOT_PORT:-8080}:8080"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      neo4j:
        condition: service_healthy
      milvus:
        condition: service_healthy
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - graphrag-network

  # FastAPI - AI服务
  fastapi:
    build:
      context: ./backend/fastapi
      dockerfile: Dockerfile
    container_name: graphrag-fastapi
    restart: unless-stopped
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER:-graphrag}:${POSTGRES_PASSWORD:-graphrag123}@postgres:5432/${POSTGRES_DB:-graphrag}
      REDIS_URL: redis://:${REDIS_PASSWORD:-redis123}@redis:6379/0
      MILVUS_HOST: milvus
      MILVUS_PORT: 19530
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USERNAME: neo4j
      NEO4J_PASSWORD: ${NEO4J_PASSWORD:-neo4j123}
      MINIO_ENDPOINT: http://minio:9000
      MINIO_ACCESS_KEY: ${MINIO_USER:-admin}
      MINIO_SECRET_KEY: ${MINIO_PASSWORD:-minio123456}
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      QWEN_API_KEY: ${QWEN_API_KEY}
      QWEN_EMBEDDING_MODEL: ${QWEN_EMBEDDING_MODEL:-text-embedding-v3}
      QWEN_LLM_MODEL: ${QWEN_LLM_MODEL:-qwen-max}
      QWEN_RERANKER_MODEL: ${QWEN_RERANKER_MODEL:-qwen-reranker}
    volumes:
      - ./logs/ai:/app/logs
      - ./models:/app/models:ro
    ports:
      - "${FASTAPI_PORT:-8000}:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      neo4j:
        condition: service_healthy
      milvus:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - graphrag-network

  # ==================== 网关层 ====================
  
  # Nginx - 前端和反向代理
  nginx:
    image: nginx:alpine
    container_name: graphrag-nginx
    restart: unless-stopped
    volumes:
      - ./frontend/dist:/usr/share/nginx/html:ro
      - ./config/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./config/nginx/conf.d:/etc/nginx/conf.d:ro
      - ./logs/nginx:/var/log/nginx
    ports:
      - "${NGINX_HTTP_PORT:-80}:80"
      - "${NGINX_HTTPS_PORT:-443}:443"
    depends_on:
      - springboot
      - fastapi
    networks:
      - graphrag-network

  # ==================== 监控层（可选） ====================
  
  # Prometheus - 指标采集
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: graphrag-prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
    volumes:
      - ./config/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    networks:
      - graphrag-network

  # Grafana - 可视化
  grafana:
    image: grafana/grafana:10.2.2
    container_name: graphrag-grafana
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin123}
      GF_INSTALL_PLUGINS: redis-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./config/grafana/provisioning:/etc/grafana/provisioning:ro
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    depends_on:
      - prometheus
    networks:
      - graphrag-network

# ==================== 网络配置 ====================
networks:
  graphrag-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

# ==================== 数据卷配置 ====================
volumes:
  postgres_data:
  redis_data:
  minio_data:
  etcd_data:
  milvus_minio_data:
  milvus_data:
  neo4j_data:
  neo4j_logs:
  neo4j_import:
  neo4j_plugins:
  zookeeper_data:
  zookeeper_logs:
  kafka_data:
  prometheus_data:
  grafana_data:
```

#### 3.2.2 创建环境变量文件

```bash
# /opt/graphrag/.env
# ==================== 数据库配置 ====================
POSTGRES_USER=graphrag
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_DB=graphrag
POSTGRES_PORT=5432

REDIS_PASSWORD=your_redis_password_here
REDIS_PORT=6379

NEO4J_PASSWORD=your_neo4j_password_here
NEO4J_HTTP_PORT=7474
NEO4J_BOLT_PORT=7687

MILVUS_PORT=19530
MILVUS_METRICS_PORT=9091

# ==================== 对象存储配置 ====================
MINIO_USER=admin
MINIO_PASSWORD=your_minio_password_here
MINIO_API_PORT=9000
MINIO_CONSOLE_PORT=9001

# ==================== 消息队列配置 ====================
KAFKA_PORT=9092

# ==================== 应用服务配置 ====================
SPRINGBOOT_PORT=8080
FASTAPI_PORT=8000
SPRING_PROFILES_ACTIVE=prod

# ==================== 网关配置 ====================
NGINX_HTTP_PORT=80
NGINX_HTTPS_PORT=443

# ==================== AI服务配置 ====================
QWEN_API_KEY=your_qwen_api_key_here
QWEN_EMBEDDING_MODEL=text-embedding-v3
QWEN_LLM_MODEL=qwen-max
QWEN_RERANKER_MODEL=qwen-reranker

# ==================== 安全配置 ====================
JWT_SECRET=your_jwt_secret_key_at_least_256_bits
JWT_EXPIRATION=86400000

# ==================== 监控配置 ====================
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000
GRAFANA_USER=admin
GRAFANA_PASSWORD=your_grafana_password_here
```

#### 3.2.3 启动服务

```bash
# 进入项目目录
cd /opt/graphrag

# 拉取镜像
docker compose pull

# 启动所有服务
docker compose up -d

# 查看服务状态
docker compose ps

# 查看服务日志
docker compose logs -f

# 查看特定服务日志
docker compose logs -f springboot
docker compose logs -f fastapi
```

### 3.3 Kubernetes部署（生产环境）

#### 3.3.1 创建命名空间

```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: graphrag
  labels:
    name: graphrag
    environment: production
```

#### 3.3.2 创建配置映射

```yaml
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: graphrag-config
  namespace: graphrag
data:
  SPRING_PROFILES_ACTIVE: "prod"
  MILVUS_HOST: "milvus.graphrag.svc.cluster.local"
  MILVUS_PORT: "19530"
  NEO4J_URI: "bolt://neo4j.graphrag.svc.cluster.local:7687"
  REDIS_HOST: "redis-master.graphrag.svc.cluster.local"
  KAFKA_BOOTSTRAP_SERVERS: "kafka.graphrag.svc.cluster.local:9092"
  MINIO_ENDPOINT: "http://minio.graphrag.svc.cluster.local:9000"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: springboot-config
  namespace: graphrag
data:
  application-prod.yml: |
    server:
      port: 8080
    spring:
      datasource:
        url: jdbc:postgresql://postgres.graphrag.svc.cluster.local:5432/graphrag
        username: ${POSTGRES_USER}
        password: ${POSTGRES_PASSWORD}
        hikari:
          maximum-pool-size: 20
          minimum-idle: 5
      redis:
        host: redis-master.graphrag.svc.cluster.local
        port: 6379
        password: ${REDIS_PASSWORD}
        lettuce:
          pool:
            max-active: 20
            max-idle: 10
    logging:
      level:
        root: INFO
        com.graphrag: DEBUG
```

#### 3.3.3 创建密钥

```yaml
# k8s/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: graphrag-secrets
  namespace: graphrag
type: Opaque
stringData:
  POSTGRES_USER: "graphrag"
  POSTGRES_PASSWORD: "your_secure_password"
  REDIS_PASSWORD: "your_redis_password"
  NEO4J_PASSWORD: "your_neo4j_password"
  MINIO_ACCESS_KEY: "admin"
  MINIO_SECRET_KEY: "your_minio_password"
  JWT_SECRET: "your_jwt_secret_key"
  QWEN_API_KEY: "your_qwen_api_key"
```

#### 3.3.4 部署Spring Boot服务

```yaml
# k8s/springboot-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: springboot
  namespace: graphrag
  labels:
    app: springboot
spec:
  replicas: 3
  selector:
    matchLabels:
      app: springboot
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels:
        app: springboot
    spec:
      containers:
      - name: springboot
        image: your-registry/graphrag-springboot:v1.0.0
        ports:
        - containerPort: 8080
        envFrom:
        - configMapRef:
            name: graphrag-config
        - secretRef:
            name: graphrag-secrets
        env:
        - name: SPRING_DATASOURCE_USERNAME
          valueFrom:
            secretKeyRef:
              name: graphrag-secrets
              key: POSTGRES_USER
        - name: SPRING_DATASOURCE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: graphrag-secrets
              key: POSTGRES_PASSWORD
        resources:
          requests:
            cpu: "500m"
            memory: "1Gi"
          limits:
            cpu: "2000m"
            memory: "4Gi"
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        volumeMounts:
        - name: logs
          mountPath: /app/logs
      volumes:
      - name: logs
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: springboot
  namespace: graphrag
spec:
  selector:
    app: springboot
  ports:
  - port: 8080
    targetPort: 8080
  type: ClusterIP
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: springboot-hpa
  namespace: graphrag
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: springboot
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

#### 3.3.5 部署FastAPI服务

```yaml
# k8s/fastapi-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fastapi
  namespace: graphrag
  labels:
    app: fastapi
spec:
  replicas: 2
  selector:
    matchLabels:
      app: fastapi
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels:
        app: fastapi
    spec:
      containers:
      - name: fastapi
        image: your-registry/graphrag-fastapi:v1.0.0
        ports:
        - containerPort: 8000
        envFrom:
        - configMapRef:
            name: graphrag-config
        - secretRef:
            name: graphrag-secrets
        resources:
          requests:
            cpu: "500m"
            memory: "2Gi"
          limits:
            cpu: "4000m"
            memory: "8Gi"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        volumeMounts:
        - name: models
          mountPath: /app/models
          readOnly: true
        - name: logs
          mountPath: /app/logs
      volumes:
      - name: models
        persistentVolumeClaim:
          claimName: models-pvc
      - name: logs
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: fastapi
  namespace: graphrag
spec:
  selector:
    app: fastapi
  ports:
  - port: 8000
    targetPort: 8000
  type: ClusterIP
```

#### 3.3.6 部署Ingress

```yaml
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: graphrag-ingress
  namespace: graphrag
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "100m"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  tls:
  - hosts:
    - graphrag.yourdomain.com
    secretName: graphrag-tls
  rules:
  - host: graphrag.yourdomain.com
    http:
      paths:
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: springboot
            port:
              number: 8080
      - path: /ai
        pathType: Prefix
        backend:
          service:
            name: fastapi
            port:
              number: 8000
      - path: /
        pathType: Prefix
        backend:
          service:
            name: frontend
            port:
              number: 80
```

#### 3.3.7 部署命令

```bash
# 创建命名空间
kubectl apply -f k8s/namespace.yaml

# 创建配置和密钥
kubectl apply -f k8s/configmap.yaml
kubectl apply -f k8s/secrets.yaml

# 部署数据库（使用Helm或Operator）
helm install postgresql bitnami/postgresql -n graphrag -f values-postgres.yaml
helm install redis bitnami/redis -n graphrag -f values-redis.yaml
helm install milvus milvus/milvus -n graphrag -f values-milvus.yaml
helm install neo4j neo4j/neo4j -n graphrag -f values-neo4j.yaml
helm install kafka bitnami/kafka -n graphrag -f values-kafka.yaml

# 部署应用服务
kubectl apply -f k8s/springboot-deployment.yaml
kubectl apply -f k8s/fastapi-deployment.yaml

# 部署Ingress
kubectl apply -f k8s/ingress.yaml

# 检查部署状态
kubectl get all -n graphrag
kubectl get pods -n graphrag -w
```

---

## 4. 配置文件说明

### 4.1 Spring Boot配置

```yaml
# application-prod.yml
server:
  port: 8080
  shutdown: graceful

spring:
  application:
    name: graphrag-business
  
  # 数据源配置
  datasource:
    url: jdbc:postgresql://${POSTGRES_HOST:localhost}:${POSTGRES_PORT:5432}/${POSTGRES_DB:graphrag}
    username: ${POSTGRES_USER}
    password: ${POSTGRES_PASSWORD}
    driver-class-name: org.postgresql.Driver
    hikari:
      maximum-pool-size: 20
      minimum-idle: 5
      idle-timeout: 300000
      connection-timeout: 30000
      max-lifetime: 1800000
  
  # Redis配置
  data:
    redis:
      host: ${REDIS_HOST:localhost}
      port: ${REDIS_PORT:6379}
      password: ${REDIS_PASSWORD}
      database: 0
      lettuce:
        pool:
          max-active: 20
          max-idle: 10
          min-idle: 5
          max-wait: -1ms
  
  # Kafka配置
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: all
      retries: 3
    consumer:
      group-id: graphrag-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      auto-offset-reset: earliest
  
  # 文件上传配置
  servlet:
    multipart:
      max-file-size: 100MB
      max-request-size: 100MB

# MyBatis Plus配置
mybatis-plus:
  mapper-locations: classpath*:/mapper/**/*.xml
  type-aliases-package: com.graphrag.entity
  configuration:
    map-underscore-to-camel-case: true
    log-impl: org.apache.ibatis.logging.slf4j.Slf4jImpl

# JWT配置
jwt:
  secret: ${JWT_SECRET}
  expiration: ${JWT_EXPIRATION:86400000}
  header: Authorization
  prefix: "Bearer "

# MinIO配置
minio:
  endpoint: ${MINIO_ENDPOINT:http://localhost:9000}
  access-key: ${MINIO_ACCESS_KEY}
  secret-key: ${MINIO_SECRET_KEY}
  bucket-name: graphrag

# Neo4j配置
neo4j:
  uri: ${NEO4J_URI:bolt://localhost:7687}
  username: ${NEO4J_USERNAME:neo4j}
  password: ${NEO4J_PASSWORD}

# Milvus配置
milvus:
  host: ${MILVUS_HOST:localhost}
  port: ${MILVUS_PORT:19530}

# 日志配置
logging:
  level:
    root: INFO
    com.graphrag: DEBUG
    org.springframework.web: INFO
    org.springframework.security: INFO
  file:
    name: /app/logs/application.log
  pattern:
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"

# Actuator配置
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: when_authorized
  metrics:
    tags:
      application: ${spring.application.name}
```

### 4.2 FastAPI配置

```python
# config.py
from pydantic_settings import BaseSettings
from functools import lru_cache

class Settings(BaseSettings):
    # 应用配置
    APP_NAME: str = "GraphRAG AI Service"
    APP_VERSION: str = "1.0.0"
    DEBUG: bool = False
    
    # 数据库配置
    DATABASE_URL: str = "postgresql://graphrag:password@localhost:5432/graphrag"
    REDIS_URL: str = "redis://:password@localhost:6379/0"
    
    # Milvus配置
    MILVUS_HOST: str = "localhost"
    MILVUS_PORT: int = 19530
    MILVUS_COLLECTION: str = "doc_chunks"
    
    # Neo4j配置
    NEO4J_URI: str = "bolt://localhost:7687"
    NEO4J_USERNAME: str = "neo4j"
    NEO4J_PASSWORD: str = "password"
    
    # MinIO配置
    MINIO_ENDPOINT: str = "localhost:9000"
    MINIO_ACCESS_KEY: str = "admin"
    MINIO_SECRET_KEY: str = "password"
    MINIO_BUCKET: str = "graphrag"
    MINIO_SECURE: bool = False
    
    # Kafka配置
    KAFKA_BOOTSTRAP_SERVERS: str = "localhost:9092"
    KAFKA_TOPIC_DOCUMENT: str = "document-process"
    KAFKA_TOPIC_EXTRACTION: str = "knowledge-extraction"
    
    # Qwen API配置
    QWEN_API_KEY: str = ""
    QWEN_API_BASE: str = "https://dashscope.aliyuncs.com/api/v1"
    QWEN_EMBEDDING_MODEL: str = "text-embedding-v3"
    QWEN_LLM_MODEL: str = "qwen-max"
    QWEN_RERANKER_MODEL: str = "qwen-reranker"
    
    # Embedding配置
    EMBEDDING_DIMENSION: int = 1024
    EMBEDDING_BATCH_SIZE: int = 32
    
    # 检索配置
    VECTOR_SEARCH_TOP_K: int = 100
    GRAPH_SEARCH_MAX_HOPS: int = 3
    RERANK_TOP_K: int = 10
    
    # LLM配置
    LLM_MAX_TOKENS: int = 4096
    LLM_TEMPERATURE: float = 0.7
    LLM_STREAM_TIMEOUT: int = 60
    
    # 日志配置
    LOG_LEVEL: str = "INFO"
    LOG_FILE: str = "/app/logs/ai-service.log"
    
    class Config:
        env_file = ".env"
        case_sensitive = True

@lru_cache()
def get_settings() -> Settings:
    return Settings()
```

### 4.3 Nginx配置

```nginx
# nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 65535;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time"';
    
    access_log /var/log/nginx/access.log main;
    
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    
    # Gzip压缩
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml application/json application/javascript 
               application/xml application/xml+rss text/javascript application/x-javascript;
    gzip_min_length 1000;
    
    # 安全头
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;
    
    # 上传大小限制
    client_max_body_size 100M;
    
    # 代理缓冲
    proxy_buffer_size 128k;
    proxy_buffers 4 256k;
    proxy_busy_buffers_size 256k;
    
    # 上游服务器
    upstream springboot {
        server springboot:8080;
        keepalive 32;
    }
    
    upstream fastapi {
        server fastapi:8000;
        keepalive 32;
    }
    
    # 包含站点配置
    include /etc/nginx/conf.d/*.conf;
}
```

```nginx
# conf.d/default.conf
server {
    listen 80;
    server_name localhost;
    
    # 前端静态文件
    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
        try_files $uri $uri/ /index.html;
        
        # 静态资源缓存
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
        }
    }
    
    # Spring Boot API
    location /api/ {
        proxy_pass http://springboot/api/;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_set_header Connection "";
        
        # 超时设置
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }
    
    # FastAPI AI服务
    location /ai/ {
        proxy_pass http://fastapi/;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_set_header Connection "";
        
        # SSE流式输出支持
        proxy_buffering off;
        proxy_cache off;
        chunked_transfer_encoding on;
        
        # 超时设置（LLM生成可能较长）
        proxy_connect_timeout 300s;
        proxy_send_timeout 300s;
        proxy_read_timeout 300s;
    }
    
    # SSE流式接口
    location /ai/chat/stream {
        proxy_pass http://fastapi/chat/stream;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header Connection "";
        
        # SSE配置
        proxy_buffering off;
        proxy_cache off;
        chunked_transfer_encoding on;
        proxy_read_timeout 86400s;
    }
    
    # 健康检查
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
    
    # 错误页面
    error_page 500 502 503 504 /50x.html;
    location = /50x.html {
        root /usr/share/nginx/html;
    }
}
```

### 4.4 Prometheus配置

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'graphrag-prod'
    environment: 'production'

alerting:
  alertmanagers:
  - static_configs:
    - targets:
      - alertmanager:9093

rule_files:
  - /etc/prometheus/rules/*.yml

scrape_configs:
  # Prometheus自身
  - job_name: 'prometheus'
    static_configs:
    - targets: ['localhost:9090']
  
  # Spring Boot服务
  - job_name: 'springboot'
    metrics_path: '/actuator/prometheus'
    static_configs:
    - targets: ['springboot:8080']
    relabel_configs:
    - source_labels: [__address__]
      target_label: instance
      replacement: 'springboot'
  
  # FastAPI服务
  - job_name: 'fastapi'
    metrics_path: '/metrics'
    static_configs:
    - targets: ['fastapi:8000']
    relabel_configs:
    - source_labels: [__address__]
      target_label: instance
      replacement: 'fastapi'
  
  # PostgreSQL Exporter
  - job_name: 'postgres'
    static_configs:
    - targets: ['postgres-exporter:9187']
  
  # Redis Exporter
  - job_name: 'redis'
    static_configs:
    - targets: ['redis-exporter:9121']
  
  # Milvus
  - job_name: 'milvus'
    static_configs:
    - targets: ['milvus:9091']
  
  # Neo4j
  - job_name: 'neo4j'
    static_configs:
    - targets: ['neo4j:2004']
  
  # Kafka
  - job_name: 'kafka'
    static_configs:
    - targets: ['kafka-exporter:9308']
  
  # Node Exporter
  - job_name: 'node'
    static_configs:
    - targets: ['node-exporter:9100']
  
  # cAdvisor
  - job_name: 'cadvisor'
    static_configs:
    - targets: ['cadvisor:8080']
```

---

## 5. 数据库初始化

### 5.1 PostgreSQL初始化

```sql
-- init/sql/01_schema.sql
-- 创建扩展
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pg_trgm";

-- 创建枚举类型
CREATE TYPE document_status AS ENUM ('pending', 'parsing', 'chunking', 'embedding', 'kg_building', 'completed', 'failed');
CREATE TYPE user_role AS ENUM ('super_admin', 'admin', 'knowledge_mgr', 'user', 'guest');

-- 用户表
CREATE TABLE users (
    id VARCHAR(64) PRIMARY KEY DEFAULT uuid_generate_v4()::text,
    username VARCHAR(64) NOT NULL UNIQUE,
    password VARCHAR(256) NOT NULL,
    email VARCHAR(128) UNIQUE,
    phone VARCHAR(20),
    real_name VARCHAR(64),
    avatar VARCHAR(512),
    status VARCHAR(32) DEFAULT 'active',
    role user_role DEFAULT 'user',
    department_id VARCHAR(64),
    last_login_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by VARCHAR(64),
    updated_by VARCHAR(64)
);

CREATE INDEX idx_users_username ON users(username);
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_status ON users(status);

-- 角色表
CREATE TABLE roles (
    id VARCHAR(64) PRIMARY KEY DEFAULT uuid_generate_v4()::text,
    name VARCHAR(64) NOT NULL UNIQUE,
    code VARCHAR(64) NOT NULL UNIQUE,
    description TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 权限表
CREATE TABLE permissions (
    id VARCHAR(64) PRIMARY KEY DEFAULT uuid_generate_v4()::text,
    name VARCHAR(64) NOT NULL,
    code VARCHAR(128) NOT NULL UNIQUE,
    resource_type VARCHAR(32),
    resource_id VARCHAR(64),
    action VARCHAR(32),
    description TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 角色-权限关联表
CREATE TABLE role_permissions (
    role_id VARCHAR(64) REFERENCES roles(id) ON DELETE CASCADE,
    permission_id VARCHAR(64) REFERENCES permissions(id) ON DELETE CASCADE,
    PRIMARY KEY (role_id, permission_id)
);

-- 文档表
CREATE TABLE documents (
    id VARCHAR(64) PRIMARY KEY DEFAULT uuid_generate_v4()::text,
    title VARCHAR(512) NOT NULL,
    source VARCHAR(512),
    doc_type VARCHAR(32),
    file_path VARCHAR(1024),
    file_size BIGINT,
    file_hash VARCHAR(64),
    content_hash VARCHAR(64),
    status document_status DEFAULT 'pending',
    metadata JSONB DEFAULT '{}',
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by VARCHAR(64) REFERENCES users(id),
    updated_by VARCHAR(64)
);

CREATE INDEX idx_documents_status ON documents(status);
CREATE INDEX idx_documents_type ON documents(doc_type);
CREATE INDEX idx_documents_created ON documents(created_at);
CREATE INDEX idx_documents_created_by ON documents(created_by);

-- 文档片段表
CREATE TABLE document_chunks (
    id VARCHAR(64) PRIMARY KEY DEFAULT uuid_generate_v4()::text,
    doc_id VARCHAR(64) NOT NULL REFERENCES documents(id) ON DELETE CASCADE,
    content TEXT NOT NULL,
    position INT,
    token_count INT,
    embedding_id VARCHAR(64),
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_chunks_doc ON document_chunks(doc_id);
CREATE INDEX idx_chunks_embedding ON document_chunks(embedding_id);

-- 实体表
CREATE TABLE entities (
    id VARCHAR(64) PRIMARY KEY DEFAULT uuid_generate_v4()::text,
    name VARCHAR(256) NOT NULL,
    type VARCHAR(64) NOT NULL,
    description TEXT,
    alias JSONB DEFAULT '[]',
    embedding_id VARCHAR(64),
    neo4j_id VARCHAR(64),
    confidence FLOAT DEFAULT 1.0,
    source_doc_id VARCHAR(64) REFERENCES documents(id),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_entities_name ON entities(name);
CREATE INDEX idx_entities_type ON entities(type);
CREATE INDEX idx_entities_source ON entities(source_doc_id);
CREATE INDEX idx_entities_neo4j ON entities(neo4j_id);

-- 关系表
CREATE TABLE relations (
    id VARCHAR(64) PRIMARY KEY DEFAULT uuid_generate_v4()::text,
    head_entity_id VARCHAR(64) NOT NULL REFERENCES entities(id),
    tail_entity_id VARCHAR(64) NOT NULL REFERENCES entities(id),
    relation_type VARCHAR(64) NOT NULL,
    evidence TEXT,
    neo4j_id VARCHAR(64),
    confidence FLOAT DEFAULT 1.0,
    source_chunk_id VARCHAR(64) REFERENCES document_chunks(id),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_relations_head ON relations(head_entity_id);
CREATE INDEX idx_relations_tail ON relations(tail_entity_id);
CREATE INDEX idx_relations_type ON relations(relation_type);

-- 对话历史表
CREATE TABLE chat_history (
    id VARCHAR(64) PRIMARY KEY DEFAULT uuid_generate_v4()::text,
    session_id VARCHAR(64) NOT NULL,
    user_id VARCHAR(64) NOT NULL REFERENCES users(id),
    role VARCHAR(32) NOT NULL,
    content TEXT NOT NULL,
    references JSONB DEFAULT '[]',
    evidence_chains JSONB DEFAULT '[]',
    feedback INT,
    feedback_comment TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_chat_session ON chat_history(session_id);
CREATE INDEX idx_chat_user ON chat_history(user_id);
CREATE INDEX idx_chat_created ON chat_history(created_at);

-- 审计日志表
CREATE TABLE audit_logs (
    id VARCHAR(64) PRIMARY KEY DEFAULT uuid_generate_v4()::text,
    user_id VARCHAR(64),
    username VARCHAR(64),
    action VARCHAR(64) NOT NULL,
    resource_type VARCHAR(64),
    resource_id VARCHAR(64),
    details JSONB DEFAULT '{}',
    ip_address VARCHAR(64),
    user_agent TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_audit_user ON audit_logs(user_id);
CREATE INDEX idx_audit_action ON audit_logs(action);
CREATE INDEX idx_audit_created ON audit_logs(created_at);
CREATE INDEX idx_audit_resource ON audit_logs(resource_type, resource_id);

-- 系统配置表
CREATE TABLE system_config (
    id VARCHAR(64) PRIMARY KEY DEFAULT uuid_generate_v4()::text,
    config_key VARCHAR(128) NOT NULL UNIQUE,
    config_value TEXT,
    description TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 创建更新时间触发器
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ language 'plpgsql';

-- 为需要的表添加触发器
CREATE TRIGGER update_users_updated_at BEFORE UPDATE ON users FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
CREATE TRIGGER update_documents_updated_at BEFORE UPDATE ON documents FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
CREATE TRIGGER update_entities_updated_at BEFORE UPDATE ON entities FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
CREATE TRIGGER update_system_config_updated_at BEFORE UPDATE ON system_config FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
```

```sql
-- init/sql/02_initial_data.sql
-- 初始化管理员用户
INSERT INTO users (id, username, password, email, real_name, role, status) VALUES
('admin', 'admin', '$2a$10$N.zmdr9k7uOCQb376NoUnuTJ8iAt6Z5EHsM8lE9lBOsl7iAt6Z5EH', 'admin@example.com', '系统管理员', 'super_admin', 'active');

-- 初始化角色
INSERT INTO roles (id, name, code, description) VALUES
('role_super_admin', '超级管理员', 'super_admin', '拥有系统全部权限'),
('role_admin', '系统管理员', 'admin', '管理系统配置和用户'),
('role_knowledge_mgr', '知识管理员', 'knowledge_mgr', '管理文档和知识库'),
('role_user', '普通用户', 'user', '使用问答和查看文档'),
('role_guest', '访客', 'guest', '仅可使用问答功能');

-- 初始化权限
INSERT INTO permissions (id, name, code, resource_type, action) VALUES
('perm_doc_create', '创建文档', 'doc:create', 'document', 'create'),
('perm_doc_read', '查看文档', 'doc:read', 'document', 'read'),
('perm_doc_update', '更新文档', 'doc:update', 'document', 'update'),
('perm_doc_delete', '删除文档', 'doc:delete', 'document', 'delete'),
('perm_kg_manage', '管理知识图谱', 'kg:manage', 'knowledge_graph', 'manage'),
('perm_chat_query', '问答查询', 'chat:query', 'chat', 'query'),
('perm_user_manage', '用户管理', 'user:manage', 'user', 'manage'),
('perm_sys_config', '系统配置', 'sys:config', 'system', 'config');

-- 分配角色权限
INSERT INTO role_permissions (role_id, permission_id) VALUES
-- 超级管理员拥有全部权限
('role_super_admin', 'perm_doc_create'),
('role_super_admin', 'perm_doc_read'),
('role_super_admin', 'perm_doc_update'),
('role_super_admin', 'perm_doc_delete'),
('role_super_admin', 'perm_kg_manage'),
('role_super_admin', 'perm_chat_query'),
('role_super_admin', 'perm_user_manage'),
('role_super_admin', 'perm_sys_config'),
-- 系统管理员
('role_admin', 'perm_doc_create'),
('role_admin', 'perm_doc_read'),
('role_admin', 'perm_doc_update'),
('role_admin', 'perm_doc_delete'),
('role_admin', 'perm_chat_query'),
('role_admin', 'perm_user_manage'),
-- 知识管理员
('role_knowledge_mgr', 'perm_doc_create'),
('role_knowledge_mgr', 'perm_doc_read'),
('role_knowledge_mgr', 'perm_doc_update'),
('role_knowledge_mgr', 'perm_doc_delete'),
('role_knowledge_mgr', 'perm_kg_manage'),
('role_knowledge_mgr', 'perm_chat_query'),
-- 普通用户
('role_user', 'perm_doc_read'),
('role_user', 'perm_chat_query'),
-- 访客
('role_guest', 'perm_chat_query');

-- 初始化系统配置
INSERT INTO system_config (config_key, config_value, description) VALUES
('embedding_model', 'text-embedding-v3', 'Embedding模型'),
('llm_model', 'qwen-max', 'LLM模型'),
('reranker_model', 'qwen-reranker', 'Reranker模型'),
('vector_search_top_k', '100', '向量检索Top-K'),
('graph_search_max_hops', '3', '图遍历最大跳数'),
('rerank_top_k', '10', '重排Top-K'),
('max_upload_size', '104857600', '最大上传文件大小(字节)'),
('allowed_file_types', 'pdf,doc,docx,md,txt', '允许上传的文件类型');
```

### 5.2 Milvus初始化

```python
# init/milvus_init.py
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility

def init_milvus():
    # 连接Milvus
    connections.connect(host='localhost', port='19530')
    
    # 文档片段向量集合
    if not utility.has_collection('doc_chunks'):
        fields = [
            FieldSchema(name='id', dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, dim=1024),
            FieldSchema(name='doc_id', dtype=DataType.VARCHAR, max_length=64),
            FieldSchema(name='chunk_id', dtype=DataType.VARCHAR, max_length=64),
            FieldSchema(name='content', dtype=DataType.VARCHAR, max_length=8192),
            FieldSchema(name='metadata', dtype=DataType.JSON)
        ]
        schema = CollectionSchema(fields, description='Document chunks collection')
        collection = Collection('doc_chunks', schema)
        
        # 创建索引
        index_params = {
            'metric_type': 'COSINE',
            'index_type': 'IVF_FLAT',
            'params': {'nlist': 1024}
        }
        collection.create_index('embedding', index_params)
        print('Created collection: doc_chunks')
    
    # 实体向量集合
    if not utility.has_collection('entities'):
        fields = [
            FieldSchema(name='id', dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, dim=1024),
            FieldSchema(name='entity_id', dtype=DataType.VARCHAR, max_length=64),
            FieldSchema(name='entity_name', dtype=DataType.VARCHAR, max_length=256),
            FieldSchema(name='entity_type', dtype=DataType.VARCHAR, max_length=64)
        ]
        schema = CollectionSchema(fields, description='Entities collection')
        collection = Collection('entities', schema)
        
        index_params = {
            'metric_type': 'COSINE',
            'index_type': 'IVF_FLAT',
            'params': {'nlist': 512}
        }
        collection.create_index('embedding', index_params)
        print('Created collection: entities')
    
    print('Milvus initialization completed')

if __name__ == '__main__':
    init_milvus()
```

### 5.3 Neo4j初始化

```cypher
// init/neo4j_init.cypher
// 创建约束
CREATE CONSTRAINT doc_id IF NOT EXISTS FOR (d:Document) REQUIRE d.id IS UNIQUE;
CREATE CONSTRAINT chunk_id IF NOT EXISTS FOR (c:Chunk) REQUIRE c.id IS UNIQUE;
CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:Entity) REQUIRE e.id IS UNIQUE;

// 创建索引
CREATE INDEX entity_name IF NOT EXISTS FOR (e:Entity) ON (e.name);
CREATE INDEX entity_type IF NOT EXISTS FOR (e:Entity) ON (e.type);
CREATE INDEX chunk_embedding IF NOT EXISTS FOR (c:Chunk) ON (c.embedding_id);

// 创建全文索引（用于实体搜索）
CALL db.index.fulltext.createNodeIndex('entitySearch', ['Entity'], ['name', 'description']);

// 创建图算法存储过程（如果需要）
// CALL gds.graph.project('entityGraph', 'Entity', 'RELATES_TO');
```

---

## 6. 服务启动与验证

### 6.1 启动顺序

```bash
#!/bin/bash
# scripts/start_services.sh

echo "=========================================="
echo "GraphRAG系统启动脚本"
echo "=========================================="

cd /opt/graphrag

# 1. 启动基础设施服务
echo "[1/4] 启动基础设施服务..."
docker compose up -d postgres redis minio
sleep 30

# 2. 启动中间件服务
echo "[2/4] 启动中间件服务..."
docker compose up -d zookeeper kafka
sleep 20
docker compose up -d etcd minio-milvus milvus
sleep 30
docker compose up -d neo4j
sleep 30

# 3. 启动应用服务
echo "[3/4] 启动应用服务..."
docker compose up -d springboot fastapi
sleep 30

# 4. 启动网关服务
echo "[4/4] 启动网关服务..."
docker compose up -d nginx

# 5. 启动监控服务（可选）
echo "[5/4] 启动监控服务..."
docker compose up -d prometheus grafana

echo "=========================================="
echo "服务启动完成"
echo "=========================================="

# 显示服务状态
docker compose ps
```

### 6.2 健康检查

```bash
#!/bin/bash
# scripts/health_check.sh

echo "=========================================="
echo "GraphRAG系统健康检查"
echo "=========================================="

# 检查PostgreSQL
echo -e "\n[PostgreSQL]"
if docker exec graphrag-postgres pg_isready -U graphrag; then
    echo "状态: 健康 ✅"
else
    echo "状态: 异常 ❌"
fi

# 检查Redis
echo -e "\n[Redis]"
if docker exec graphrag-redis redis-cli -a ${REDIS_PASSWORD:-redis123} ping | grep -q PONG; then
    echo "状态: 健康 ✅"
else
    echo "状态: 异常 ❌"
fi

# 检查Milvus
echo -e "\n[Milvus]"
if curl -s http://localhost:9091/healthz | grep -q OK; then
    echo "状态: 健康 ✅"
else
    echo "状态: 异常 ❌"
fi

# 检查Neo4j
echo -e "\n[Neo4j]"
if curl -s http://localhost:7474 | grep -q neo4j; then
    echo "状态: 健康 ✅"
else
    echo "状态: 异常 ❌"
fi

# 检查Kafka
echo -e "\n[Kafka]"
if docker exec graphrag-kafka kafka-broker-api-versions --bootstrap-server localhost:9092 &>/dev/null; then
    echo "状态: 健康 ✅"
else
    echo "状态: 异常 ❌"
fi

# 检查Spring Boot
echo -e "\n[Spring Boot]"
if curl -s http://localhost:8080/actuator/health | grep -q UP; then
    echo "状态: 健康 ✅"
else
    echo "状态: 异常 ❌"
fi

# 检查FastAPI
echo -e "\n[FastAPI]"
if curl -s http://localhost:8000/health | grep -q healthy; then
    echo "状态: 健康 ✅"
else
    echo "状态: 异常 ❌"
fi

# 检查Nginx
echo -e "\n[Nginx]"
if curl -s http://localhost/health | grep -q healthy; then
    echo "状态: 健康 ✅"
else
    echo "状态: 异常 ❌"
fi

echo -e "\n=========================================="
echo "健康检查完成"
echo "=========================================="
```

### 6.3 验证测试

```bash
#!/bin/bash
# scripts/verify_deployment.sh

BASE_URL="http://localhost"
API_URL="${BASE_URL}/api"
AI_URL="${BASE_URL}/ai"

echo "=========================================="
echo "GraphRAG系统部署验证"
echo "=========================================="

# 1. 用户登录
echo -e "\n[1] 用户登录测试"
LOGIN_RESPONSE=$(curl -s -X POST "${API_URL}/auth/login" \
    -H "Content-Type: application/json" \
    -d '{"username":"admin","password":"admin123"}')
echo "登录响应: ${LOGIN_RESPONSE}"

TOKEN=$(echo ${LOGIN_RESPONSE} | jq -r '.data.token')
echo "Token: ${TOKEN:0:20}..."

# 2. 获取用户信息
echo -e "\n[2] 获取用户信息测试"
USER_INFO=$(curl -s -X GET "${API_URL}/users/me" \
    -H "Authorization: Bearer ${TOKEN}")
echo "用户信息: ${USER_INFO}"

# 3. 上传文档测试
echo -e "\n[3] 文档上传测试"
UPLOAD_RESPONSE=$(curl -s -X POST "${API_URL}/documents/upload" \
    -H "Authorization: Bearer ${TOKEN}" \
    -F "file=@test_document.pdf")
echo "上传响应: ${UPLOAD_RESPONSE}"

DOC_ID=$(echo ${UPLOAD_RESPONSE} | jq -r '.data.doc_id')
echo "文档ID: ${DOC_ID}"

# 4. 查询文档状态
echo -e "\n[4] 文档状态查询测试"
STATUS_RESPONSE=$(curl -s -X GET "${API_URL}/documents/${DOC_ID}/status" \
    -H "Authorization: Bearer ${TOKEN}")
echo "状态响应: ${STATUS_RESPONSE}"

# 5. 向量检索测试
echo -e "\n[5] 向量检索测试"
SEARCH_RESPONSE=$(curl -s -X POST "${AI_URL}/search/vector" \
    -H "Content-Type: application/json" \
    -d '{"query":"测试查询","top_k":5}')
echo "检索响应: ${SEARCH_RESPONSE}"

# 6. 问答测试
echo -e "\n[6] 问答测试"
CHAT_RESPONSE=$(curl -s -X POST "${AI_URL}/chat/completions" \
    -H "Content-Type: application/json" \
    -d '{"query":"这是一个测试问题","stream":false}')
echo "问答响应: ${CHAT_RESPONSE}"

echo -e "\n=========================================="
echo "部署验证完成"
echo "=========================================="
```

---

## 7. 日常运维操作指南

### 7.1 服务启停

#### 7.1.1 启动服务

```bash
# 启动所有服务
docker compose up -d

# 启动单个服务
docker compose up -d springboot
docker compose up -d fastapi

# 启动服务组
docker compose up -d postgres redis neo4j milvus
```

#### 7.1.2 停止服务

```bash
# 停止所有服务
docker compose down

# 停止单个服务
docker compose stop springboot
docker compose stop fastapi

# 停止并删除容器
docker compose down --remove-orphans

# 停止并删除数据卷（危险操作）
docker compose down -v
```

#### 7.1.3 重启服务

```bash
# 重启所有服务
docker compose restart

# 重启单个服务
docker compose restart springboot
docker compose restart fastapi

# 优雅重启（等待连接关闭）
docker compose restart -t 30 springboot
```

### 7.2 状态监控

```bash
# 查看所有服务状态
docker compose ps

# 查看服务资源使用
docker stats

# 查看特定服务日志
docker compose logs -f --tail=100 springboot
docker compose logs -f --tail=100 fastapi

# 查看所有服务日志
docker compose logs -f --tail=50

# 导出日志到文件
docker compose logs --no-color > logs/system_$(date +%Y%m%d).log
```

### 7.3 配置更新

```bash
# 更新环境变量
vim .env

# 更新配置文件后重启服务
docker compose restart springboot

# 更新镜像
docker compose pull springboot
docker compose up -d springboot

# 完整更新流程
git pull
docker compose build
docker compose up -d
```

### 7.4 数据管理

```bash
# 查看数据卷使用情况
docker system df -v

# 清理未使用的数据卷
docker volume prune

# 备份数据卷
docker run --rm -v graphrag_postgres_data:/data -v $(pwd)/backup:/backup alpine tar czf /backup/postgres_$(date +%Y%m%d).tar.gz -C /data .

# 恢复数据卷
docker run --rm -v graphrag_postgres_data:/data -v $(pwd)/backup:/backup alpine tar xzf /backup/postgres_20260217.tar.gz -C /data
```

---

## 8. 监控与告警

### 8.1 监控指标

#### 8.1.1 系统指标

| 指标 | 说明 | 告警阈值 |
|------|------|---------|
| CPU使用率 | 系统CPU使用百分比 | > 80% 持续5分钟 |
| 内存使用率 | 系统内存使用百分比 | > 85% 持续5分钟 |
| 磁盘使用率 | 磁盘空间使用百分比 | > 85% |
| 磁盘IO | 磁盘读写速率 | > 80% IOPS限制 |
| 网络流量 | 网络入出流量 | > 80% 带宽限制 |

#### 8.1.2 应用指标

| 指标 | 说明 | 告警阈值 |
|------|------|---------|
| 请求QPS | 每秒请求数 | 根据容量规划 |
| 响应时间 | 请求平均响应时间 | > 3秒 |
| 错误率 | HTTP 5xx错误比例 | > 1% |
| JVM堆内存 | Java堆内存使用率 | > 80% |
| GC时间 | GC时间占比 | > 10% |
| 连接池 | 数据库连接池使用率 | > 80% |

#### 8.1.3 数据库指标

| 指标 | 说明 | 告警阈值 |
|------|------|---------|
| 连接数 | 数据库连接数 | > 80% 最大连接数 |
| 慢查询 | 慢查询数量 | > 10/分钟 |
| 复制延迟 | 主从复制延迟 | > 1秒 |
| 缓存命中率 | Redis缓存命中率 | < 80% |
| 向量检索延迟 | Milvus检索延迟 | > 100ms |
| 图遍历延迟 | Neo4j遍历延迟 | > 200ms |

### 8.2 告警规则

```yaml
# prometheus/rules/alerts.yml
groups:
- name: graphrag-alerts
  rules:
  # 系统告警
  - alert: HighCPUUsage
    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "高CPU使用率"
      description: "实例 {{ $labels.instance }} CPU使用率超过80%，当前: {{ $value }}%"
  
  - alert: HighMemoryUsage
    expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "高内存使用率"
      description: "实例 {{ $labels.instance }} 内存使用率超过85%，当前: {{ $value }}%"
  
  - alert: DiskSpaceLow
    expr: (1 - (node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"} / node_filesystem_size_bytes{fstype!~"tmpfs|overlay"})) * 100 > 85
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "磁盘空间不足"
      description: "实例 {{ $labels.instance }} 磁盘使用率超过85%，当前: {{ $value }}%"
  
  # 应用告警
  - alert: HighErrorRate
    expr: sum(rate(http_server_requests_seconds_count{status=~"5.."}[5m])) / sum(rate(http_server_requests_seconds_count[5m])) * 100 > 1
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "高错误率"
      description: "HTTP 5xx错误率超过1%，当前: {{ $value }}%"
  
  - alert: HighResponseTime
    expr: histogram_quantile(0.95, sum(rate(http_server_requests_seconds_bucket[5m])) by (le)) > 3
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "高响应时间"
      description: "P95响应时间超过3秒，当前: {{ $value }}秒"
  
  - alert: ServiceDown
    expr: up == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "服务不可用"
      description: "服务 {{ $labels.job }} 实例 {{ $labels.instance }} 不可用"
  
  # 数据库告警
  - alert: PostgreSQLDown
    expr: pg_up == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "PostgreSQL不可用"
      description: "PostgreSQL实例不可用"
  
  - alert: RedisDown
    expr: redis_up == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Redis不可用"
      description: "Redis实例不可用"
  
  - alert: MilvusDown
    expr: milvus_up == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Milvus不可用"
      description: "Milvus实例不可用"
  
  - alert: Neo4jDown
    expr: neo4j_up == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Neo4j不可用"
      description: "Neo4j实例不可用"
```

### 8.3 Grafana仪表盘

推荐导入以下仪表盘：
- **Node Exporter Full** (ID: 1860) - 系统监控
- **Spring Boot Statistics** (ID: 12900) - Spring Boot监控
- **PostgreSQL Database** (ID: 9628) - PostgreSQL监控
- **Redis Dashboard** (ID: 11835) - Redis监控
- **Milvus Dashboard** (ID: 18764) - Milvus监控

---

## 9. 日志管理

### 9.1 日志配置

#### 9.1.1 Spring Boot日志

```xml
<!-- logback-spring.xml -->
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <property name="LOG_PATH" value="/app/logs"/>
    <property name="APP_NAME" value="graphrag-springboot"/>
    
    <!-- 控制台输出 -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>
    
    <!-- 文件输出 -->
    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_PATH}/${APP_NAME}.log